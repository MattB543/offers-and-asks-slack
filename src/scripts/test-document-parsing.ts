import { promises as fs } from 'fs';
import path from 'path';
import { documentParsingService } from '../services/documentParser';

/**
 * Test script to parse a single document without database operations
 * This shows what the document processing pipeline does
 */
async function testDocumentParsing() {
  console.log('ðŸ§ª Testing document parsing pipeline...');
  
  try {
    // Get list of markdown files in drive_docs folder
    const driveDocsPath = path.join(process.cwd(), 'data', 'drive_docs');
    console.log(`ðŸ“ Looking for documents in: ${driveDocsPath}`);
    
    const files = await fs.readdir(driveDocsPath);
    const markdownFiles = files.filter(file => file.endsWith('.md'));
    
    if (markdownFiles.length === 0) {
      console.log('âŒ No markdown files found in data/drive_docs/');
      return;
    }
    
    // Test with the first document
    const testFile = markdownFiles[0];
    const filePath = path.join(driveDocsPath, testFile);
    
    console.log(`\nðŸ“„ Testing with: ${testFile}`);
    console.log('===============================================');
    
    // Parse the document (without saving to database)
    const parseResult = await documentParsingService.parseDocument(filePath);
    
    // Display results
    console.log(`\nâœ… Document Successfully Parsed!`);
    console.log(`ðŸ“Š Title: ${parseResult.title}`);
    console.log(`ðŸ“Š Document ID: ${parseResult.documentId}`);
    console.log(`ðŸ“Š Total chunks: ${parseResult.chunks.length}`);
    console.log(`ðŸ“Š File size: ${parseResult.metadata.fileSize} bytes`);
    console.log(`ðŸ“Š Processing time: ${parseResult.metadata.processingTime}ms`);
    
    if (parseResult.metadata.originalFilePath) {
      console.log(`ðŸ“Š Original path: ${parseResult.metadata.originalFilePath}`);
    }
    
    console.log(`\nðŸ“ Summary (${parseResult.summary.length} chars):`);
    console.log(parseResult.summary.substring(0, 200) + '...');
    
    console.log(`\nðŸ§© Chunk breakdown:`);
    const chunkTypes = parseResult.chunks.reduce((acc, chunk) => {
      acc[chunk.chunkType] = (acc[chunk.chunkType] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    
    Object.entries(chunkTypes).forEach(([type, count]) => {
      console.log(`  - ${type}: ${count} chunks`);
    });
    
    console.log(`\nðŸ“„ Sample chunks:`);
    parseResult.chunks.slice(0, 3).forEach((chunk, i) => {
      console.log(`\n  Chunk ${i + 1} (${chunk.chunkType}):`);
      if (chunk.sectionTitle) {
        console.log(`    Section: ${chunk.sectionTitle}`);
      }
      console.log(`    Level: ${chunk.hierarchyLevel}`);
      console.log(`    Keywords: ${chunk.metadata.keywords.join(', ')}`);
      console.log(`    Content: ${chunk.content.substring(0, 150)}...`);
    });
    
    console.log(`\nðŸŽ‰ Test completed successfully!`);
    console.log(`ðŸ’¡ Run "npm run process-documents" when database is available to process all ${markdownFiles.length} documents`);
    
  } catch (error) {
    console.error('âŒ Test failed:', error);
  }
}

// Run the test
if (require.main === module) {
  testDocumentParsing().catch(error => {
    console.error('ðŸ’¥ Unhandled error:', error);
    process.exit(1);
  });
}

export { testDocumentParsing };