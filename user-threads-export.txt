Blake: I missed the boat on making a lab notes channel, and just did it. But I notice 1) I don't know if I can put it in the right section, and 2) I don't know that I can invite everyone to it so they can see it, without pinging a notification to everyone. Anyone know who knows the protocol?
Me: I think a Slack admin has to move it and set it up for you in the right way (@Niki Dupuis if you hard coded a list of lab note channels you might have to add this one)
---
Alexander: Got this UX working yesterday - useful to get a sense of the sort of thing we're working on. I'm getting the ux populated with a more realistic run rather than this stub data. Obvious things to do in the future with various levels of priority: • there is much more that can be done on a single scenario analysis • add a multi-run workflow - where instead of setting up a single scenario, we do many at the same time. Both by branching of within a scenario and by changing the underlying assumptions of a run. ◦ that also adds a whole new dimension for analysis • benchmarking is prob pretty high prio in the next step. As in; does the backend actually result in realistic trajectories? In useful trajectories? Everything else is downstream of this • The way to ingest the action information is pretty bland. you just end up reading a bunch. Prob better ways to do this. • Adding a "pick your own stakeholder" game mode, where you play against the AIs as whatever stakeholder.
Alexander: feedback / hot takes welcome.
Me: Random feedback (understanding that this is MVP V1) 1. there is going to be a ton of data / text / info to keep track of, spending time figuring out exactly what layouts / views / graphs are most helpful and how to easily hide / expand necessary info when needed will be important a. I felt like this was a limitation in the IRL AI 2027 - I didn't feel like I had access to much data at all, other than the small conversations I was in, or the post-it notes that were read 2. Final world state - it would be interesting to show how the hidden dynamics affected actions / outcomes a. Did the stakeholders figure out / guess / accommodate for these hidden dynamics? b. Did they miss key implications because of these dynamics 3. Very small UI/UX idea is to have the AI pick an icon / emoji for each bullet point, for like the key outcomes a. [handshake] Wyoming-Japan parternship b. [chartwithdownwards_trend] China's market share reduced c. etc.
Alexander: Thoughtful Matt! Thanks Yeah interesting especially about the dynamics analysis. There is something in there for me about really rewarding running tests and experiments in game, and updating with new info - in the way I would hope we would in reality
Me: Interesting to think that after you run it the first time with a group, they'll then understand the hidden dynamics so you'd either have to generate new hidden dynamics for the re-run or understand that they will now more correctly model the hidden stuff
---
Luke: Curious to hear people's current setup for giving LLMs context on their lives (inspired by nuno's neat script in the linked thread). Also interested to hear how everybody feels about privacy concerns etc -- I'm excited by local models but I feel like I might be in the minority here!
Me: I think this is a very important/valuable topic and underdiscussed! LLMs get so much better with more quality relevant context, so I feel like even in this fellowship we're not saving/managing context as well as we should. For instance, ideally every call (with consent) should be recorded and have a notes doc and they should both be dropped into an LLM with a particular fellowship-related prompt to summarize it. Then we could have an every growing broad context about everything we're all talking about and working on I asked @Niki Dupuis to scrape every public Slack channel every day and I'm storing it in my Offers and Asks DB so I can improve the quality of the analysis of fellows and their skills --- But back to personal context. What I've done is: 1. taken the clearer thinking personality (https://www.clearerthinking.org/tools/the-ultimate-personality-test) test a. I asked for them to export all of my questions and answers, so I have all of those + the full report (Big Five, Enneagram, MBTI, etc. etc.) My report here (https://mattbrooks.xyz/personalityreport/) 2. taken this Saboteurs (Self-Sabotage) test (https://www.positiveintelligence.com/saboteurs/) 3. fed in my resume 4. then, used voice to ramble about my life in chronological order, talking about the different items that feel important to who I am, how I turned out, what I care about, etc. for about ~15 mins 5. created a twitter scraper (https://github.com/MattB543/analyze-twitter-profile) to parse my tweets, twitter likes and bookmarks and replies a. The output is 800k tokens I tossed into Gemini to summarize. That output is here (https://mattbrooks.xyz/twitteranalysis/) 6. Threw all of the above into GPT-4.5 and asked it what items I'm neglecting to share that would help it understand me better and did a few back and forths on that I'm trying to build up like 100k very high quality dense tokens about me in a way that would very much help AIs: 1. Negotiate on my behalf / share my preferences with others easier 2. Give me very specific advice / recommendations 3. Help me find biases or areas for growth (it's good at this! it can point out your shadows)
Me: --- I think this has really great potential to be a project for the fellowship - or a piece of a project. I think high quality personal context matters so much and has so many valuable use cases How could you trust an amazing negotiator bot to help you if the LLM doesn't fully understand you, your values, your context, history, personality etc.!?
Alex: Super interesting, thanks for sharing, Matt! Re personal context: It totally makes sense to me that you're experimenting with this. I'd be curious to hear any specific anecdotes about where this provided value for you. And curious to hear if you think this is "a reasonable thing you might want to try out" versus "everyone should absolutely make the time to do this".
Me: I don't think I've gotten a ton of high value out of doing this yet, but I do enjoy introspection / self-study anyway, so it's been generally fun / interesting I hope / expect the future value will come from plugging my extensive personal context into tools to personalize the output/flows So if I'm building some distillation modules I can say like "Pull out the information I'll find most interesting" Or "most confusing / most disagreeable" It would be basically impossible do that flow without great personal context, but will be trivial for me now Also, I plan to publish all of the personal context I'm willing to share publicly on my website and hopefully AI agents in the future can find it easily and use that info to interact with me and my agents better, etc.
Alex: > Also, I plan to publish all of the personal context I'm willing to share publicly on my website and hopefully AI agents in the future can find it easily and use that info to interact with me and my agents better, etc. This is an interesting idea, and potentially worth prioritizing while next-word-prediction pre-training is still a thing. Feels like there are pros and cons to an AI knowing a lot about who you are and how your mind works (thinking less about misalignment here, where there'd be bigger things to worry about, and more about other people or companies being better able to manipulate you or gain an information advantage). But more pros?
Me: Yeah, I totally understand there are pros and cons, but I think there are enough positive sum stuff I want to get into, and I can hopefully mitigate the cons with like AI assisted epistemics (like the agent @Luke Hewitt was talking about that helps spot bias or manipulation), so it seems likely very beneficial
Me: Oh and I started but haven't finished these questions, as well: https://ggia.berkeley.edu/practice/36questionsforincreasingcloseness
---
Luke: Random idea: 1. Make a #poll channel, where where we can post questions and people answer with emoji-reactions. 2. Make a slackbot that comes up with a couple of interesting new polls every day that people might be split on (perhaps based on topics people have been discussing)
Me: I really like this idea! What if we started with a more official/detailed survey: • AI takes / timelines / etc. • AI for human reasoning takes / clusters / projects / focuses / impact stories? • A little bit of personal bio / skills / experiences (for the asks and offers bot and future bots/agents?) • Questions that FLF leadership wants to add for their sake Then once we analyze that survey we can find cruxes or interesting follow up questions and post them like once a day automatically in this poll channel
---
NunoSempere-cli: The decisionmate workflow reminds me of the delphi method; you might want to look into that! https://en.wikipedia.org/wiki/Delphi_method
Nuno: More thoughts: • Current demo shows users typing, but talking is much faster
Gordon: +1 I've used variations of Delphi before as part of scenario workshops with large numbers of participants.
Alex: > • Current demo shows users typing, but talking is much faster This is one of my biggest concerns. I agree that talking is much faster and where this will need to go. Have you seen good implementations of two-way voice interfaces? The things I've tried feel very clunky to me, even chatgpt's advanced voice mode. I'm hoping they will get better soon (e.g. ~6 months), but have uncertainty about that.
Me: it's easy to have a built-in audio-in feature in your app instead of typing, so people can just click the mic button and record their rambling and then it transcribes That would be the very easy V1, but idk how much people prefer talking to typing, but giving them the option seems nice
---
TownCrier: Hi! I'm not ready to make summaries yet, but here's the raw data from today's lab-notes scrape [blush] If you'd like to experiment with it, be my guest!
Me: @Niki Dupuis if I create a route in my Offers and Asks app, can you POST all of the raw data to it, so I can save it and use it in my DB? Are you doing a scrape every few hours or so, to get around the limited history allowance?
Me: Oh, you're limited on 15 objects and 1 request per min, but you can set the oldest or latest params to control the timeframe
Niki: Right, so I grab 15 at a time, once a minute. I was planning to just have the script spin up once a day. But sure, I'm happy to post that data to you!
Me: oh, what if someone posts more than 15 messages in a day? also, I'm thinking I might want to scrape all messages from all public channels..... what do you think of that?
Niki: No, like I just scrape in batches of 15 until I've gone as far back as 7 days
Niki: So I'll get everything, it just slows things down
Me: I meant not even just lab notes channels, but all public channels (even new ones as they're created)
---
Elizabeth: [sparkles][books]Book Recommendations[books][sparkles]:
Elizabeth: @Kathleen Finlinson @Blake Borgeson
Me: Blake's suggestion was "Reinventing Organizations" I think Kathleen's was "Tao Te Ching"?
---
Ben: @Sofi (or anyone else) if you're interested in building a new pivotal workflow, take a look at this function: https://github.com/cooperativetech/pivotal/blob/main/src/anthropic-api.ts#L260 Basically the idea is that it takes as arguments the current topic summary (e.g. a topic is "let's schedule a meeting for next week"), and all historical slack messages relevant to that topic, as well as the latest message sent that the bot can see (which triggers the function call). It then returns a set of updates to the topic summary or set of users involved, as well as a list of next messages to send either in DMs or to the group. Pretty much all you have to do for a new workflow is to write a new one of these functions that corresponds to your desired workflow, the rest of topic tracking + slack bot minutiae should be handled by the backend. That said, it's kind of difficult to make sure the bot does the right thing given all the conversational context, so we're working on more testing + evaluation tools now, which should be generalizable to multiple types of workflows
Me: @Ben Sklaroff how did you build the Slack message scraping thing? @Niki Dupuis was hitting crazy rate limits on that. Like 1 request a minute or something
---
Me: Random thought... if OpenAI indeed buys itself out from under the non-profit, won't the non-profit have many billions of dollars, believe in relatively short timelines, and want to quickly fund projects that raise human reasoning/epistemics/governance/etc.? Off of that thought... the apparent bottleneck for OpenPhil is the ability to evaluate grants I believe they don't have the time/manpower to evaluate many hundreds of small grants (like <$10k or something) And reviewing large grants takes a bunch of time Wouldn't a personalized platform/agent/flow powered by GPT-5 be able to cut down on man hours by like 50% or something? Couldn't this "grant evaluation" thing be used for other impact-oriented funders? Maybe the OpenAI non-profit in the future? The idea would be to unlock many billions of dollars that want to support x-risk in the next few years but don't have a good way to evaluate people/projects Also, if a warning shot or more billionaires wake up to the AI risks over the next couple of years, the money that wants to flow into mitigating X-risk might like 5x but the bottleneck woudl still be grant evaluations / follow ups / etc. Does FLF have this sort of problem? Would they be interested in using a tool like this? @user
Ben: 1.) The situation you're pointing at - an influx of new philanthropic dollars into AI safety - is very real. Regardless of what happens with OAI, I'm betting on massive amounts of capital coming into the space from gvts, companies, and other foundations over the next few years. 2.) Improvements to grant evaluators would be a great use case for things like AI research tools, AI forecasters, etc. 3.) I'd be interested in using such a tool (how we leverage Uplift for FLF's core workflows is a recurring questions/topic!) 4.) However, note of caution: I often feel like the problem is not that we're bottlenecked on grant evaluation in a traditional sense: it's more that we're bottlenecked on ambitious fundable plans that have been de-risked to the point that we can put meaningful dollars into them. If this is of interest I can put you in contact with some of the creators of https://manifund.substack.com/p/announcing-manival
Ben: (I haven't seriously tried it, I'd be interested in evals around it - another area where epistemic evals would help...)
Me: > However, note of caution: I often feel like the problem is not that we're bottlenecked on grant evaluation in a traditional sense: it's more that we're bottlenecked on ambitious fundable plans that have been de-risked to the point that we can put meaningful dollars into them. Yeah, I agree with this, although it's probably a harder problem to solve and takes more time (upskilling, incubating, community growth, etc.) I actually hadn't seen Manival, that's super cool, I'll take a look
Ben: I agree with Ben that it's possible that the area will get a lot more funding but OpenAI does not seem likely to make a foundation which "believes in relatively short timelines, and want to quickly fund projects that raise human reasoning/epistemics/governance/etc". They have been pretty explicit about the money going to mainstream art, health, etc. nonprofits, particularly those in california. A cynical reader may interpret this as an attempt to buy off the california AG who needs to approve their conversion.
Ben: > it's more that we're bottlenecked on ambitious fundable plans that have been de-risked to the point that we can put meaningful dollars into them +1, I've talked to some other funders who feel like there is not much to fund in the space which is very impactful. Although I think it's worth noting that there is kind of a chicken and egg problem where people don't want to start projects because they don't want to be tied to OP and then as a result there is nothing to fund
Me: > They have been pretty explicit about the money going to mainstream art, health, etc. nonprofits, particularly those in california. My own naive outside view is that they say this because if they say anything else it angers too many people/politicians/everyone I would expect the non-profit board to be pretty AGI-pilled and would want to reduce x-risk because there are a ton of other players that will build healthcare/education stuff automatically --- > +1, I've talked to some other funders who feel like there is not much to fund in the space which is very impactful. Although I think it's worth noting that there is kind of a chicken and egg problem where people don't want to start projects because they don't want to be tied to OP and then as a result there is nothing to fund I agree and think this is a massive bottleneck, but might be pretty hard to solve. Very open to ideas/projects that could push on this. It seems like one of the bigger potential levers you could push if you could find something tractable. Quick prompt: why isn't OpenPhil trying to ideate/iterate/explore this bottleneck? Maybe they are, but I haven't heard to much about it. I've heard they don't want to say this out loud because if they say "there's not enough good projects" it pisses off people that they deny funding AND it disincentives people starting projects AND if they try to open the door more to potential ideas they just get more crap
Ben: hmm, I feel like OP is working on this? Like they invest a lot of their time in RFPs and active grant making which they wouldn't need to do if they had a stream of impactful grants coming in
Ben: I guess they don't say "we are spending our time coming up with lists of projects you should do because y'all are too dumb to come up with it yourselves" but I think that's the subtext
Me: > they invest a lot of their time in RFPs and active grant making which they wouldn't need to do if they had a stream of impactful grants coming in This is one way - to kind of hand hold in a more top-down way, but that doesn't seem very scalable. If AI Safety money 10xs in the next 3 years, could that approach 10x? Could it generalize to other orgs/Gov? Could someone build an environment to fine-tune GPT-5 on all of OpenPhils documents/writing/RFPs so that once they identify a space they want to fund they can spin up a high quality RFP in 30 mins? But also, it's interesting (and sad) that none of the (few) bottom-up methods have really been pushed hard on, mostly they haven't worked well, or there hasn't been appetite
Ben: Oh yeah the AI assistant thing seems great, I was just commenting that I think the assistant should be something more like "causes other people to apply with good ideas" rather than "filters the applications for good ideas"
Me: Ah, yeah I totally agree, ideally it should do both, as both sides of the problem could be a huge bottleneck in the near future (and maybe even currently)
---
Niki: ugh I'm not facing some kind of limit, where when I read from a channel it only lets me get max 15 messages (no matter how high I set the limit). Claude code thinks this is my fault somehow, tells me the limit should be 100
Niki: ah
Me: Might be worth it to use my db and run the job every hour to scrape 15 messages max on a recurring basis
---
Me: My Slack App MVP "Offers and Asks" is live!! [rocket] [fire] [rocket] [fire] [rocket] [fire] Please test it out and give me feedback. Just <slack://app?team=T093YGRN8R2&id=A098T3WPQRH&tab=messages|go to the app> and DM it something like "I need help making an MVP quickly" and it will reply in a thread to your message with the 5 most likely people that can help you with that task based on their assumed skills, like so: (you can edit / add your skills from the app home tab)
Me: Lightning Talk Feedback: • Seth: create clusters around readings/content/sources ◦ surprising connections. 14 people all mentioned/cited this paper • Alex: there could be more connection happening and my direction is decent, he was thinking about this. There are likely other people that are feeling a bit lost. Quickly identify "this person might want to work on this thing, I could write up a spec and chat about it". You might want "potentially promising interactions" - instead of perfect matches we should find weird/interesting overlap in people.
---
Me: Anyway, after fixing that last bug, my Slack App MVP is live!! [rocket] [fire] [rocket] [fire] [rocket] [fire] Please test it out and give me feedback. Just <slack://app?team=T093YGRN8R2&id=A098T3WPQRH&tab=messages|go to the app> and DM it something like "I need help making an MVP quickly" and it will reply in a thread to your message with the 5 most likely people that can help you with that task based on their assumed skills, like so:
Niki: it works!
Niki: unsettling how fast that was though
Niki: like did it even make an api call?
Me: Yeah, kinda crazy, it has to make one gpt-4.1 call and then match the embedding. Quicker than I thought it would be though
Ben: the link didn't work for me in the browser, had to go here: https://app.slack.com/client/T093YGRN8R2/D099TCBTWRW
Me: Oh true, that deep link might only work in the slack app What kind of monster uses slack in the browser though? [laughing]
---
Me: Does anyone have a good/easy method to give Claude Code access to your DB? (maybe read only if you're scared) So it can check schema/ data/ etc. automatically?
Alex: Are you finding it struggles using the command line? Do you have examples in Claude.md?
Me: I've never really tried it tbh, it can run postgres queries directly in command line? Do you put your DB URL in claude.md and tell it to fire off queries? Is this somewhere in their documentation? Should be a standard flow, right?
---
Kai: One thing I have noticed is that it looks like a number of different groups are thinking about coordination projects that feel related: @user and @user are programming a Slack Bot for relatively granular decisions, @user and @user are aiming at automating the "2-hr meeting" level complexity of decision, and for deliberation my thinking was to look at more complex outputs (like contracts, code-bases etc) where the bottleneck is helping people focus their attention on which parts are most relevant to them. It feels like the basic piping behind the scenes will be quite similar for all of these. Without wanting to introduce additional complexity, I wonder if that means there would be scope for building out a joint back-end. Perhaps worth thinking about depending on how the different explorations go!
Parker: https://github.com/cooperativetech/pivotal Our github is public, see here
Me: @user if you can make it to breakouts in 20 mins we're aiming to have a breakout about this exact topic!
Kai: Hey, sorry another meeting ran over and I just missed this! What was the take-away? [slightlysmilingface]
Me: We talked a lot and typed a lot into this doc: https://docs.google.com/document/d/1R5nRqfHcXJtKfoylsMTh0jn43dKrth5mwZ9StZzCj3w/edit?tab=t.0 @user has the meeting recording (if it's possible, can you add a link to that to the top of the notes doc?) I think: • two groups will likely think somewhat separately and hack away for now • Potential for shared infra in the future • groups / ideas are definitely still in flux • short term product and long term impact goals aren't nailed down, but there are many thoughts/opinions in the air
---
Me: A cool v3 of your bot @Niki Dupuis is to scrape everything in every lab notes channel, save it to a DB, an let people search / query / chat with the DB
Me: actually, saving all of that data in a DB would help me a lot because I could use it to improve the skills/offers in my dataset (you could even use my DB and just create your own tables if you want)
---
Tamera: I’m feeling in a bit of a (likely temporary) slump with the TTX project. I’m setting up the initial version now, and I think I may just be putting slightly too many constraints on myself: • Great architecture (I’m very happy with this part tbh) • New-to-me tech stack w/ partykit (which I am still learning) • Feel like I need to be creating something polished for a large group of people to provide feedback on (which feels hard to make go well at this stage) • Coding it up by myself, not on a team • Wanting to have a better automated coding workflow than I do / feeling like I’m moving more slowly than I should, or producing lower-quality work than I want to I think maybe the main issue is some implicit feeling of pressure to move faster and have more done than I do, which paradoxically makes it hard to make progress. I’ve typically found it easier to move fast on personal projects, where I don’t have the imagined board room of stakeholders looming over me in my mind [upsidedownface] any one of whom could have an objection or request which I didn’t happen to prioritize. Or working on a team, with established standards, and people to talk to when needed. I imagine I’ll move past this soon, but I thought it might be nice to share some of the lowlights as well as highlights. I’m also open to anybody’s reactions, thoughts, or advice here!
Tamera: I’m already getting a sense of what a better plan might be to move forward from here: don’t build this repo as though it will be the final perfect version. Just build it to be what it needs to be right now, and learn from that - it’s an MVP. As time goes on we’ll learn and have a better sense of how exactly to implement everything so that it’s as stable and scalable as it is in my dreams
Owen: When I've hit issues with momentum that rhyme with this, I've often found that at some level it's a kind of logjam where I have some explicit belief about what the next step "should" be, but another part of me doesn't fully believe in that and is unwilling to defer. Unjamming sometimes comes from by-myself making space for enough meta that I can tune into what I actually feel about next steps; also bringing someone in to talk things through with and bounce ideas off can help (partially just because it helps with social permissioning to spend time at the meta level, but also because other perspectives can help to move me out of a rut or directly help). Not sure how idiosyncratic this is! At least sometimes I think this advice has been helpful to others, but do ignore if it feels wrong-shaped. Also as I was writing it you said you've found a better plan already which is great. Guess I'll still share in case the general model helps any.
Me: Also, once you have a somewhat crappy but working MVP it's much easier with AI to build a cleaner/better version iterating in the right direction So I totally agree with "don’t build this repo as though it will be the final perfect version"
---
Niki: @Timothy Telleen-Lawton Can I get takes on whether I should do: Option 1: Rolling 7 day window, daily summary covers everything you need to know about the big picture of what people are working on Option 2: Daily report only tells you about the last 24 hours (and to see more info you previous reports, posted in the same channel) I'm leaning toward 1, cause I hate scrolling up in a channel to find old things? But I realize it might be really annoying to see the same stuff posted every day for 7 days.
Niki: My thinking is: For someone who checks every day they'd prefer 2, but for people who don't they might prefer 1?
Me: you could post a messages like these (and make them better obviously) "Tues 08/05/25 24 Hour Report" And then put the 24 hour report in a thread on that message And then every Monday morning you could also post "Mon 08/04/25 Weekly Report" And put the full previous week report in that thread? So it's very easy to scroll and click into different threads (not cluttered)
---
Nathan: A problem with community notes is not knowing which sources are trustworthy. Seems like an increasing problem as it becomes cheaper to put up a fake but official looking site
Ben: https://www.tracingwoodgrains.com/p/reliable-sources-how-wikipedia-admin I think this is true and it's like this article on how a wiki admin has abused the "reliable sources" aspect of wikipedia
Ben: or, maybe its the inverse of it! in that community notes doesn't have a canonical list, so instead you have maybe a proliferation of spam sites
Nathan: Yes I think it’s probably the inverse.
Me: I think "citation score/trustworthiness" is a great problem to work on, and might fall into the <#C097Z6QB9QD|> toolkit idea, @user Sooo many people/projects/flows could benefit from: • Verifying a citation is truly saying what is claimed it said (easy - this is the deep research analysis idea you have) • Fact checking the citation and giving it a quality/truthfulness score (could be hard but super valuable)
---
Niki: Ok next hurdle: Slack api rate limits. Anyone dealt with that already?
Me: ohhh crap... they just updated that I think https://api.slack.com/changelog/2025-05-terms-rate-limit-update-and-faq Btw, it takes months to get approved for the Slack marketplace I think you'll just have to work around it, like start your job at 5 AM and analyze the previous days messages very slowly
---
Martin: TLDR: Reverse image searching a photo to find when it first appeared online is sometimes - but is usually not - the only piece of information needed for a community note. Reverse image searching would likely need to be part of a larger AI pipeline to make this into a useful bot. @user and I have been experimenting with what pieces of the pipeline are actually needed and which are easiest to build. What we're currently working on: Developing a reverse image search system for X Community Notes to help combat misinformation by identifying when old or misattributed images are being shared as current events Key challenges discovered so far: Cost constraints • Existing reverse image search APIs are expensive to use ($200 for 5000 images) ◦ Related: Could we potentially develop an image indexer within X itself to document when an image first shows up on X and its related content? This might be very useful for @user and I to potentially build as shared infra for other community note bot teams and the broader community notes ecosystem cc @user Not enough sample data in the community notes test database • When we first joined last week, there was a total of 20 tweets with images that community notes were being requested for • Now it's at 200, but we've found some issues • Very few of these actually yield useful community notes when reverse image searched ◦ (but is non-zero. Probably 1-5% on the upper end, perhaps this is still significant) To increase our success rate, we'd need to solve additional cases like (just brainstorming/calling them out, not saying that we would do them): • Is this image AI generated? • After reverse image searching, crawl and parse the websites to see if the image is still there • Check if the context on the website differs from the tweet (many cited sources won't even show the same image anymore) Difficult to identify candidates • From tweet text alone, it's hard to determine which images would benefit from reverse image searching (we would need an LLM to look at the image and provide context to what it shows) • Figuring out what exact prompt to give an LLM alongside the image, to help narrow down if this is a good candidate for reverse image searching is tricky (loads of edge cases)
Me: "Is this image AI generated?" is a tool that @user would highly benefit from, I believe
---
Emma: Update from the past weekend: TL;DR have a side project I plan to pursue + have tentatively positively updated on the ease of using local government as a testbed for AI x policy/govt ideas • Went to a tech for SF hackathon (my first hackathon!) • Won it, with a vibecoded website (we're truly in a golden era for “idea guys”) • The project was an open platform for govt, technologists, and civic actors to post ideas/requests for civic tech projects and get feedback/collaborators/advisors/end users (as well as for govt actions/policies to better leverage tech or collaborate better with the civic tech community). • Given a new more pro-tech mayor recently came in, there’s a lot of activity around tech x SF govt; I appear to have maybe successfully inserted myself into that/possibly preempted some of it with the platform. We’ve been invited to discuss it with the Mayor’s Office of Innovation, some of the Board of Supervisors, and one or two new/relaunching public-private initiatives. • Don’t think this will require more than a few hours a week from me to continue to pursue, and has some direct benefits for my fellowship work: ◦ Its a platform for coordination + collective intelligence, so a testbed for ideas relating to that. I have some ways I want to try using AI to help with that (though I don’t think AI is necessarily the core lever here). ◦ It’ll help refine my understanding of paths for adoption/distribution of AI4HR tech into government ◦ It’s offering good surface area expansion/networking, and in particular will get me relationships with local govt & civic tech realm that could help offer testbeds for my (or others’) AI4HR projects, where that’s useful (e.g., for public input style tools)
Me: "Its a platform for coordination + collective intelligence, so a testbed for ideas relating to that. I have some ways I want to try using AI to help with that (though I don’t think AI is necessarily the core lever here)." Does this sound similar to the small group agent-based decision making / coordination apps that <#C098TMQ9XT5|> and <#C097XRT3BSP|> are looking to build? It would be sick to build an awesome MVP and get it in front of SF gov people. Obviously don't want to hijack your idea/project, but I'm sure some people would love to help you build something if you already have a use-case/audience in mind (I would be happy to help)
Emma: @Matt Brooks maybe? here's the mockup website to give you a sense of where we're going with the project (SF OS) https://preview--idea-forge-nation.lovable.app/; if you think theres potential to integrate your work into the website, super excited to hear. (But also if your work's not an exact fit for integration into SF OS as a platform, but there's civic applications for it, then would encourage you to use SF OS (once its officially up) to post your work on there, to see if ppl adopt it/build upon it further!)
Me: ahh, now I fully get it, very slick for a hackathon, well done!
---
Luke: [ai4hr mapping/deliberation] It'd be interesting to poll us all on a bunch of high-level questions (AI predictions, interest in various projects, theories of impact, etc), see what correlates with what, and then repeat the survey in a couple of months and see how everybody has shifted.
Me: I really like this idea, it would be really great to find divergent world/impact views or cruxes now, to maybe attempt to resolve them or make it more clear which projects are attempting what things
Luke: Cool if you have thoughts on particular questions you think would be good to include drop 'em here and I can make a poll later this week
Me: I think this could be pretty valuable/interesting but it might take a fair amount of thought/work to come up with really good questions, etc. I'll think about it some today and send a doc and we could book a call later this week to brainstorm or something
---
Timothy: Thinking a lot about what structures are most useful for Fellows. Currently considering eliminating the cohort-wide activities in the afternoon for the second half of the week (Starting Wednesday) and keeping the morning sessions (LT wed, Breakouts Thu, LT Fri)
Me: I have some thoughts/questions/ideas on this, would you like to book a quick 1 on 1 later today? Maybe 15 mins just after the breakout group if you're free?
Me: actually @user, I'll chat with Ben in gathertown after the breakout, feel free to join if you want!
---
Me: @Rob Gordon do you have the fellow data you used for this https://ai4hr-fellow-flashcards.vercel.app/ in a format you can easily share with me?
Rob: Yeah! It's in airtable. Do you want to DM me your e-mail address and I'll add you to the airtable. Then you should be able to create an API token and pull it (and/or just export it)
Me: sick - <mailto:matthewrbrooks94@gmail.com|matthewrbrooks94@gmail.com>
Me: I trust these crazy fellows w/ my email, lol
---
Me: Here's my WIP for a Slack bot that helps automate offers & asks: https://github.com/MattB543/offers-and-asks-slack
Ben: this is cool! currently Pivotal doesn't store any long-term user-specific context -- it just tracks all the ongoing conversations in slack around a given topic (e.g. scheduling a specific event). you got me thinking about how to make that topic history a queryable source of user info (e.g. user skill sets), so that it could potentially serve this use case as well
Me: Do you have a channel or doc with your thoughts, ideas, plans, etc. For pivotal?
---
Gordon: These days, I'm always running a meta-process in my head where if I start working on a task, I stop, frame the task as a prompt, and let the AI take a first crack at the problem. Sometimes I even run the meta-meta-process and let the AI define what the task should be from my stream-of-consciousness braindump.
Gordon: The future of work feels like it's going to be figuring out which layer of meta you should be on for a given task. More layers as models get smarter.
Me: yes, I think this is underused. I'm a huge supporter of getting your ego out of the way and use AI to help you think/plan better
---
U0980RYU7JT: https://en.wikipedia.org/wiki/Folieàdeux ; shared psychosis. Could be relevant to predicting AI superpersuasion
Gordon: Another signal might be tightness of the feedback loop between person and AI. Generally, the tighter the loop, the greater the synchronization between systems, and the part of the system with the most variety will control the direction of the combined system https://en.m.wikipedia.org/wiki/Variety(cybernetics)#Lawofrequisitevariety (https://en.m.wikipedia.org/wiki/Variety(cybernetics)#Lawofrequisitevariety)
Me: yeah this is def why it's happening now that Chat-GPT has memory. Tighter feedback loop. Imagine if memory + personalization is 10x improved next year, there could be a lot of danger about falling into a blackhole with an AI
---
Niki: Hi <!subteam^S0941SE8AG5>! I've made a thing I would really really like you to see / contribute to. It's an interactive map of existing projects in the AI for Human Reasoning space, which is intended to support you in discovering prior work you might not have known about. It's very rough, but in the spirit of working in public I'm releasing a public link now. I plan to continue to maintain and update/improve this map throughout the fellowship. It would be very helpful if you could share projects that I've missed, either by using the feedback form on the site, or by sharing that with me via slack. Hope you discover something new [heart] The Map: https://cute-cascaron-fcc2d6.netlify.app/ Codebase: https://github.com/nickkeesG/AI4HR_Map
Me: Would my AI Safety Feed count? https://aisafetyfeed.com/
Me: a filterable table view would be cool, if it's easy to build
---
Me: I'll put the plan that I wrote out during one of the kickoff events in this thread, although it's subject to change a lot
Me: *Project Ideas:* - Epistemic Evals - Read everything Lukas has written or linked to - Come back to this: https://docs.google.com/document/d/1bZKLW2Yaiw__VOPioL9b6oAWXomFQdvayV8Zny3CMc0/edit?tab=t.0#heading=h.603h3k4gas08 - Figure out the theory of change potential (to limit the search scope below) - evals are hot - maybe they're oversupplied - labs will be eval shopping? - Find eval aggregators, directories, lists - Understand the eval space broadly - Most popular evals - Longest lasting - Eval posting orgs - Common structures - Tips / warnings / gotchas / guides - Find posts of people discussing eval results, building evals, critiquing evals (Less Wrong, etc.) - Book a call with all of the people in the fellowship that are interested in this - Write my ideas/questions in the eval Slack - Once I gather the above, write a doc or book a call with Lukas to confirm my ideas or clear up my confusions and help me plan on MVP - How to get people to care? - Orgs (gov and not Gov) have calls for proposals for evals - Alignment Project - Open Phil - calls for proposals - Cause areas usually increase eval - Distill Toolkit - Have another discussion with the people interested in this topic sync and async to understand: - What is the impact story? - anyone using it for citations would be good? - What is the short term and long term goals? - What parts of the idea would we collab a lot on and share VS what parts of the project are going to splinter - How could this project best help other fellowship projects? - library manager for tools other groups are building? - Nathan - Getting stuff for prediction markets - What is out there already? Do research with the group to understand better the current playing field - What can we steal / copy / improve? - Existence proof of people looking to use tools like this - How does can this toolkit be set up or built out to also help the eval idea at the same time? - Automated evals for citation checking - Automated eval for finding logical flaws - Automated eval for finding biased language?? - STEP: Set up a call with Elicit - Are we a competitor? - https://aisafetyfeed.com/ - Show it off in the demo channel, explain it as a project to see if anyone else is interested in the general concept, get feedback, etc. - Keep it running in a basic sense until the build phase - It could be used as a test bed for distill toolkit, etc.
---
Tamera: Question for the organizers: can I use the compute stipend to pay for a fancier version of Claude Code to use during the fellowship? It’s $100-$200 per month depending on the tier
Me: I asked this during a Q&A and they said yes Claude Code counts as compute you can expense
---
Kathleen: Optional lightning talks are starting soon in a conference room on floor 3 (or in gather.town (https://app.gather.town/app/4ZfRZorTe9gHg6nD/RSP-library))
Me: did there happen to be notes / recordings?
---
Joshua: thanks @user @user @user @user @user @user @user! if you have further thoughts do drop here or in the doc and I’ll review [pray]
Kathleen: piggy-backing off this list of pings… Do any of you have feedback / ideas about the use of Google Docs as a collaboration tool during this meeting? Or other ideas about how the group discussion went? Feel free to reply here or DM me [slightlysmilingface]
Paul: I thought it was good, not sure if there are other better options, happy to try new things if people have ideas.
Kathleen: One of my thoughts is that Google Meet might work better than gather.town once we finish the “checkin” part of the meeting and break into smaller groups (although we didnt’ have enough people to break into multiple groups today)
Kathleen: Seems like Matt had some issues with gather.town for example
Kathleen: Another of my thoughts: It might be helpful to try the “hand/finger” moderation system (people write in the chat “hand” if they want to make a new point, and “finger” if they want to say something that’s a subtopic on the current discussion; the moderator calls on the hands in order but calls on the fingers before moving to the next hand)
Kathleen: At any rate, I was happy to see the discussion today; it seemed fruitful!
Me: @user I'd prefer google meet or zoom just so we could invite an ai recorder to transcribe so the notes are complete and guaranteed. But that's just my opinion
---
Nathan: Here is a 2 minute poll for the stuff I’m doing about community notes. Would value people’s votes. https://viewpoints.xyz/polls/10x-community-notes
Josh: I feel like I’d value an optional “weigh my opinion low / high / very high” for people to use when appropriate. Someone might eg “know the answer” but that won’t show up in this poll (of course they optimally message you about that, but there’s also versions less extreme than knowing).
Me: Or what if there was a slider on each question with 3 options: • Low confidence, med confidence, high confidence Defaults to med but you could change it for each question. If you switch it to high confidence then future questions default to that (maybe you're an expert) --- And is there a benefit from having strongly agree? 5 point scale, or not really? Just two thumbs down, one thumbs down, neutral, one thumbs up, two thumbs up. Wouldn't take up more space cause you're removing the text in the buttons unless you think that's necessary Obviously don't want to make it a more complicated tool if the value-add isn't there for these features Tagging in @Rob Gordon
---
Kathleen: Hi everyone! I hope everyone’s travels are going well, that you’re all getting some appropriate rest after an intense few days, and that you’re excited to keep the progress going! Just some notes on the next steps regarding fellowship programming, x-posted from email (see thread):
Me: Can we (should we?) Create a meta-fellowship channel or something, to talk about process, etc.?
---
Alyssia: Feeling excited! First time I’ve ever made a lab notes channel like this so it feels cool. Working on scoping a few projects to ship quickly in the next week or two-ish, starting with getting our community notes bot live on X! Other areas I’m looking to scope in next: • An experiment in coordination/epistemics for specs, h/t @user and his DARPA excitement! • Epistemic evals (epistemic arena of sorts? a quick scoped eval in consistency implemented in inspect?) • Something in forecasting (need to map open problems in this area!) • Exploring what a semantic search/indexing API for helping people build misinformation identification tools like our X bot might look like
Me: > Exploring what a semantic search/indexing API for helping people build misinformation identification tools like our X bot might look like Does this sounds like something that would be a part of the "Distillation Toolkit (https://docs.google.com/document/d/1Re4CgEUWppjHhRqEJYixj5inEs2oNHH6cTk3BKyVZ78/edit?pli=1&tab=t.1gqrwq6luvgk)" idea that is being talked about
---
Tamera: (I see that most people are using their lab notes channels for mostly work stuff (very reasonable!) so I might move personal thoughts to another channel later on) I haven’t used slack in almost a year, and man, there are a bunch of little ways in which it has become noticeably worse to me in that time. It is so perplexing to me when successful software companies can’t seem to stop themselves from making their product worse with successive new updates - definitely an open question in my mind why this happens
Ben: I have this same question!
Ben: Why change the UI??
Tamera: I tried to make a canvas just now and the formatting was all over the place. Like nobody QA’d it at all before pushing to prod
Me: I think it's a few things, but mostly principal agent problems The dev that can convince everyone internally to "improve" the UI gets a raise/status/whatever And it might be hard or subtle to actually know the truth if it's an improvement It only takes one charismatic connected dev to push crap through. And their manager is also incentivised to make the project seem like a success, etc. Multiply that by thousands of people and its basically impossible not to trend towards slop Also tech debt, decision debt, etc.
Tamera: Sure, I can believe that in the abstract. It just seems to me like some other feedback loop would take over once things got so obviously bad on the frontend that even a nonexpert would notice and complain
Tamera: Thanks for your analysis!
Me: People could def notice, but if you don't have the status/connections/whatever to go against the charismatic guy that pushed the update, then its not in your personal interest to say anything
Me: People in this fellowship are like 3x more disagreeable than the average tech employee, lol
Me: (In a good way)
Tamera: Seems like an honest-to-god emperor’s new clothes situation. I didn’t think that kind of thing actually happened in real life, to be honest
Tamera: Thank you again for your analysis. It’s hard to know what kind of bubbles we truly live in
Seth: Internal inventive gradients at large orgs heavily and inevitably favor performative work (in particular, adding stuff)
Tamera: This is the new canvas page btw. Like, that is not subtly bad. That is really obviously bad. And when I look at this, I think the whole story can’t just be about adding new features - they have to be letting quality standards slip, too, to get here. I am so curious about what’s going on in there haha
Tamera: I wonder if there’s any firm that specializes in rescuing companies from their own internal incentive problems like this. Surely investors should stand to benefit from that?
Tamera: I guess that’s like the Bobs from office space. Presumably some firms are better than others at that task - certainly the Bobs weren’t looked at with respect in that film. I wonder how pricing and prestige work in that industry
Tamera: Even without consultants, it’s so mind-blowing to me that it could even get to this point to begin with.
Me: Canvas is new enough it might still technically be in beta phase or something, idk Or slack is now a dead player because bought by Salesforce, so any truly good devs left?
---
Alexander: Comment under here <!channel>
Me: The Distillation Toolbox We have built a doc that lists sources, links, ideas, etc. related to: > We cover distillation in the broad sense: Searching from sources of all kinds, extracting information, and finding true pieces of information in useful ways for specific use cases. https://docs.google.com/document/d/1Re4CgEUWppjHhRqEJYixj5inEs2oNHH6cTk3BKyVZ78/edit?pli=1&tab=t.1gqrwq6luvgk
---